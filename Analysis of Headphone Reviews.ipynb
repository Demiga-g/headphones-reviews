{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "416808da",
   "metadata": {},
   "source": [
    "# **About Dataset**\n",
    "\n",
    "This is a small subset of dataset of headphone reviews from Amazon. The dataset has 6 columnsðŸŽ§ðŸŽ§ðŸŽ§ðŸŽ§\n",
    "\n",
    "1. `Customer Name` -- name of customer who buy the product\n",
    "\n",
    "2. `REVIEW_TITLE` -- review in short\n",
    "\n",
    "3. `Color` -- color of the product\n",
    "\n",
    "4. `REVIEW_DATE` -- date when customer gives rating for eg: 05-Sep-21\n",
    "\n",
    "4. `COMMENTS` -- customers comment what are feeling of customer about product\n",
    "\n",
    "5. `RATINGS` -- how customer rate out of 5 star for eg: 4/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ee531a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Customer_Name                        REVIEW_TITLE  Color REVIEW_DATE  \\\n",
      "0       Ramdika       Really Exceed my expectation.  Black   30-May-21   \n",
      "1     Sachin AK  Great for a change from inear buds  Black   01-Jun-21   \n",
      "\n",
      "                                            COMMENTS  RATINGS  \n",
      "0  Okay.. I was skeptical at first to buy this as...        5  \n",
      "1  The earphone is worth what you pay for. The de...        5  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 7)\n",
    "\n",
    "headphone_reviews = pd.read_csv('headphone_data.csv')\n",
    "print(headphone_reviews.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bd48ed",
   "metadata": {},
   "source": [
    "## Acknowledgements\n",
    "\n",
    "This dataset is taken from [Kaggle](https://www.kaggle.com/datasets/mdwaquarazam/headphone-dataset-review-analysis) and from [Amazon product data](https://www.amazon.in/boat-headphones/s?k=boat+headphones)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5eaf56",
   "metadata": {},
   "source": [
    "# **Data to Use**\n",
    "\n",
    "- Since this is a sentiment analysis, we'll concentrate on the columns `REVIEW_TITLE`, `COMMENTS` and `RATINGS`. Additionally, I'll use the assumption that for ratings 4 and 5, the rating will be used as `positive` which we'll be coded as 1. For rating equal to 3, the rating will be a `neutral` hence coded as 0. Finally for ratings 2 and 1, the rating will be `negative`, thus coded 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dac810a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1538, 3)\n",
      "                         REVIEW_TITLE  \\\n",
      "0       Really Exceed my expectation.   \n",
      "1  Great for a change from inear buds   \n",
      "2      For people with sensitive ears   \n",
      "\n",
      "                                            COMMENTS  RATINGS  \n",
      "0  Okay.. I was skeptical at first to buy this as...        1  \n",
      "1  The earphone is worth what you pay for. The de...        1  \n",
      "2  Particularly for people with sensitive ears, w...        1  \n"
     ]
    }
   ],
   "source": [
    "headphone_reviews = headphone_reviews[['REVIEW_TITLE', 'COMMENTS', 'RATINGS']].dropna()\n",
    "headphone_reviews['RATINGS'] = [1 if rate >=4 else 0 if rate == 3 else 2 for rate in headphone_reviews.RATINGS]\n",
    "print(headphone_reviews.shape)\n",
    "print(headphone_reviews.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32547045",
   "metadata": {},
   "source": [
    "## String Frequency\n",
    "\n",
    "- First, wordclouds will be created to see the frequency of words in the in `COMMENTS` column both the training and testing data. From the plots it is evident that the common words used in the comments are similar in both the training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a71b230c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'string_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m all_reviews \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(headphone_reviews\u001b[38;5;241m.\u001b[39mCOMMENTS)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Setting wordcloud to plot\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m cloud_reviews \u001b[38;5;241m=\u001b[39m WordCloud(height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\u001b[38;5;241m.\u001b[39mgenerate(\u001b[43mstring_train\u001b[49m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Plotting the wordcloud\u001b[39;00m\n\u001b[0;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplots(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'string_train' is not defined"
     ]
    }
   ],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "all_reviews = ' '.join(headphone_reviews.COMMENTS)\n",
    "\n",
    "# Setting wordcloud to plot\n",
    "cloud_reviews = WordCloud(height=200).generate(string_train)\n",
    "\n",
    "# Plotting the wordcloud\n",
    "plt.subplots(figsize=(10, 6))\n",
    "plt.imshow(cloud_reviews, interpolation='bilinear')\n",
    "plt.axis('off');\n",
    "plt.title('Reviews WordCloud');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d5eb05",
   "metadata": {},
   "source": [
    "# **Provisional Model Building**\n",
    "\n",
    "For this section, we'll create a logistic regression model without any adjustments to the data and see how our model performs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c37658f",
   "metadata": {},
   "source": [
    "## Creating a Vectorized DataFrame\n",
    "\n",
    "In this section we'll use the TF-IDF Vectorizer because it penalizes most frequent words and gives weight to less frequent word in the corpus.\n",
    "\n",
    "- For now, we'll use the the functionality with its default values. Only the `COMMENTS` column has been used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c19434f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "review_vectorizer = TfidfVectorizer().fit(headphone_reviews.COMMENTS)\n",
    "comments_data = review_vectorizer.transform(headphone_reviews.COMMENTS).toarray()\n",
    "review_df = pd.DataFrame(comments_data, columns=review_vectorizer.get_feature_names_out())\n",
    "review_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2959950",
   "metadata": {},
   "source": [
    "## Training and Testing Data\n",
    "\n",
    "Eighty percent of the data will be used to train the model. The use of `train_test_split()` was settled upon despite the dataset having labels that call for a multi-class classification solution because the split data have reasonable values. \n",
    "\n",
    "- Note that the features data `X` will be the vectorized `review_df` while the labels data will be extracted from the `RATINGS` column from the `headphone_reviews` dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b4b096",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = review_df\n",
    "y = headphone_reviews.RATINGS\n",
    "\n",
    "X_train, X_test, y_train, y_test =\\\n",
    "    train_test_split(X, y, train_size=0.8, \n",
    "                     stratify=y, random_state=42)\n",
    "\n",
    "pd.DataFrame({'training_data': y_train.value_counts(), \n",
    "              'testing_data': y_test.value_counts()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6c07b3",
   "metadata": {},
   "source": [
    "## Building a Classifier\n",
    "\n",
    "Here, a logistic regression model is trained to predict sentiment. In other words, the model a logistic regression model is trained and then its performance checked on test data to see how well the model performs.\n",
    "\n",
    "- The default values are used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99878aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "prov_regressor = LogisticRegression().fit(X_train, y_train)\n",
    "y_predicted = prov_regressor.predict(X_test)\n",
    "y_predicted[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925f9cbe",
   "metadata": {},
   "source": [
    "## Accuracy of the Model\n",
    "\n",
    "- Here we use `accuracy_score` and the `confusion_matrix` to check how the logistic regression model performed. An accuracy of 0.81 is good but our model did not even predict a `negative` score.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025d563f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "print(accuracy_score(y_test, y_predicted))\n",
    "print('-'*40)\n",
    "print(confusion_matrix(y_test, y_predicted) / len(y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
